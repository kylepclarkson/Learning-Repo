{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using A CNN (and CIFAR-10)\n",
    "---\n",
    "\n",
    "In this notebook we implement a convolutional neural network to classify low quality images (from the CIFAR-10) dataset where each entry belongs to exactly one of 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get training and validation datasets from PyTorch\n",
    "# Pass both to dataloaders for sampling batches. \n",
    "\n",
    "data_path = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\data\\\\'\n",
    "# Define a transform to normalize the 3 channels of each image to 0.5 and 0.5 mean, std dev.\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(data_path, train=True, download=True,  transform=transform)\n",
    "val_set = torchvision.datasets.CIFAR10(data_path, train=False, download=True,  transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Define CNN\n",
    "###\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # take 3x32x32 --> 6x32x32 \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, padding=1)\n",
    "        # downsample 6x32x32 --> 6x16x16\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        # convolve 6x16x16 --> 8x16x16\n",
    "        self.conv2 = nn.Conv2d(6, 8, kernel_size=3, padding=1)\n",
    "        # convolve 8x16x16 --> 8x8x8\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        # flatten 8x8x8 --> 64x1\n",
    "        self.fc1 = nn.Linear(8*8*8, 64)\n",
    "        # flatten 64x1 --> 32x1\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        # flatten 64x1 --> 32x1\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        # flatten 32x1 --> 10x1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolution, activation function, and pooling to input\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # reshape x to match first linear layer\n",
    "        x = x.view(-1, 8*8*8)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper Functions, members ===\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Show image \n",
    "def imshow(img):\n",
    "    # display an image\n",
    "    img = img / 2 + 0.5 # unnormalize image to [0,1]\n",
    "    npimg = img.numpy()\n",
    "    # Display image by reordering channels to match pyplot's expectation\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "# Validation loop\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"validate\", val_loader)]:\n",
    "        correct_pred, total = 0, 0\n",
    "        # disable tracking of operations \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                # convert tensors to device\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                print('inshape: ', imgs.shape)\n",
    "                y_preds = model(imgs)\n",
    "                _, predicted = torch.max(y_preds, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                # compare agreements between predicted and labels, sum and add to running total. \n",
    "                correct_pred += int((predicted==labels).sum())\n",
    "        print(f'Accuracy: {name} {correct_pred/total:.3f}')\n",
    "        \n",
    "    return correct_pred/total\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "    # loop over epochs\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    running_loss = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        \n",
    "        # iter over training batch\n",
    "        for imgs, labels in train_loader:\n",
    "            # convert tensors to device\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            y_pred = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        running_loss.append(loss_train)\n",
    "                \n",
    "        # display results of network. Save model if better accuracy rate is achieved. \n",
    "        if epoch % 10 == 0 or epoch == 1: \n",
    "            loss = loss_train / len(train_loader)\n",
    "            print(f'{datetime.datetime.now()} Epoch: {epoch}, Training loss: {loss:.3f}')\n",
    "            \n",
    "            accuracy = validate(model, train_loader, val_loader)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                # save model \n",
    "                print(\"Saving model !\")\n",
    "                data_path = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\Learning-Repo\\\\PyTorch\\\\models\\\\'\n",
    "                torch.save(model.state_dict(), data_path+'_n_'+ str(n_epochs+1) +'cifar_10_test.pt')\n",
    "                best_accuracy = accuracy\n",
    "                \n",
    "    return running_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 12:23:50.196626 Epoch: 1, Training loss: 1.722\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n",
      "inshape:  torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-78a4824575e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-a774719f0102>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{datetime.datetime.now()} Epoch: {epoch}, Training loss: {loss:.3f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-a774719f0102>\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# disable tracking of operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[1;31m# convert tensors to device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rl\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(300, opt, model, loss_fn, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a2b7d1ec88>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n",
      "True label: cat Predicted: frog\n",
      "AxesImage(54,36;334.8x217.44)\n",
      "True label: ship Predicted: ship\n",
      "AxesImage(54,36;334.8x217.44)\n",
      "True label: ship Predicted: ship\n",
      "AxesImage(54,36;334.8x217.44)\n",
      "True label: plane Predicted: ship\n",
      "AxesImage(54,36;334.8x217.44)\n",
      "True label: frog Predicted: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load trained model\n",
    "data_path = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\Learning-Repo\\\\PyTorch\\\\models\\\\'\n",
    "torch.save(model.state_dict(), data_path+'_n_301cifar_10_test.pt')\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\Learning-Repo\\\\PyTorch\\\\models\\\\_n_301cifar_10_test.pt'))\n",
    "model.eval()\n",
    "\n",
    "for i in range(5):\n",
    "    img, label = val_set[i]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, pred = torch.max(model(img.unsqueeze(0)), dim=1)\n",
    "        imshow(img)\n",
    "        print(f'True label: {classes[label]} Predicted: {classes[pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-08e91d57ecd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-05fd8545b9c2>\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# display an image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;31m# unnormalize image to [0,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mnpimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Display image by reordering channels to match pyplot's expectation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "print(imshow(val_set[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
