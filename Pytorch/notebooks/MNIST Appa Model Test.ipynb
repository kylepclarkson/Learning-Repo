{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Trained 'Appa' Model\n",
    "\n",
    "Having trained a small CNN called 'Appa' for classifying digits, we load the saved model and test its prediction on the MNIST validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data. \n",
    "data_path = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\data\\\\'\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_set = torchvision.datasets.MNIST(data_path, train=False, download=True,  transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image of digit. \n",
    "def imshow(img):\n",
    "    # display an image\n",
    "    img = img.cpu()\n",
    "    npimg = img.numpy()\n",
    "    # Display image by reordering channels to match pyplot's expectation\n",
    "    plt.imshow(npimg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AppaNet(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout2d(p=0.3, inplace=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (dense1): Linear(in_features=392, out_features=20, bias=True)\n",
       "  (dense2): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Import Appa model class.\n",
    "path_dir = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\Learning-Repo\\\\Pytorch\\\\MNIST'\n",
    "sys.path.append(path_dir)\n",
    "\n",
    "from models import AppaNet\n",
    "\n",
    "# Load saved parameters. \n",
    "model = AppaNet()\n",
    "model.load_state_dict(torch.load(path_dir+'/models/appa_mnist.pt'))\n",
    "model.eval()\n",
    "model.to('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1955 Predicted: 2, Label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Run this cell to randomly select entry from validation set, \n",
    "display it, and test what the model classifies it as.\n",
    "'''\n",
    "index = np.random.choice(len(val_set))\n",
    "img, label = val_set[index]\n",
    "\n",
    "with torch.no_grad():\n",
    "    img = img.to('cuda:0')\n",
    "    _, pred = torch.max(model(img.unsqueeze(0)), dim=1)\n",
    "    imshow(img)\n",
    "    print(f'Index: {index} Predicted: {pred.item()}, Label: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
